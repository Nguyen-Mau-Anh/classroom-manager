# Orchestrate Dev - Layer 1 Configuration
# =========================================
# This file is auto-copied to docs/orchestrate-dev.config.yaml on first run.
# Customize the copy in docs/ folder for your project.
#
# Execution Model: HYBRID
# - BMAD workflows: Spawned as separate agents (isolated context)
# - Bash commands: Direct execution (shared context)
# - Orchestration: Parent context (coordination)
#
# Prompt Variables (for spawn stages):
#   {story_id}      - The story identifier
#   {story_file}    - Path to story file
#   {errors}        - Error output from failed command (for fix stages)
#   {files_changed} - List of changed files (for code review)
#   {autonomy}      - Auto-injected autonomy instructions
#   {project_root}  - Absolute path to project root directory

name: orchestrate-dev
version: "1.0.0"
description: "Layer 1: Story development with quality checks"
layer: 1

# Autonomy instructions injected into all prompts
autonomy_instructions: |
  AUTONOMOUS MODE - NO QUESTIONS.
  Skip all menus, confirmations, and user prompts.
  Execute the task completely and output results only.
  Do not ask follow-up questions.

# Story file locations to check (in order)
story_locations:
  - "state/stories/${story_id}.md"
  - "docs/stories/${story_id}.md"
  - "docs/sprint-artifacts/${story_id}.md"

# Knowledge Base Configuration
# Controls how lessons learned are captured and applied
knowledge_base:
  enabled: true                    # Enable/disable knowledge base system
  max_lessons_per_stage: null      # Max lessons to show per stage (null = all, 0 = all, number = limit)
  min_encounter_count: 1           # Minimum times a lesson must be seen to be included

  # Per-stage overrides (optional)
  stage_overrides:
    # lint:
    #   max_lessons: 10            # Override for specific stage
    # typecheck:
    #   max_lessons: 15

# All stages are MANDATORY
# Execution types:
#   - spawn: Run as separate agent via Task tool (for BMAD workflows)
#   - direct: Run directly in parent context (for bash commands)

stages:
  # Stage 1: Create story if file doesn't exist
  create-story:
    order: 1
    enabled: true
    execution: spawn
    type: bmad_workflow
    workflow: /bmad:bmm:workflows:create-story
    condition: story_file_not_exists
    timeout: 3600
    on_failure: abort
    description: "Create story file from epics if it doesn't exist"
    prompt: |
      /bmad:bmm:workflows:create-story
      {autonomy}

      {known_issues}

      Create the next story from the epics/backlog.
      Read the epics file and generate the story file.
      Output: story_id and story_file path.

  # Stage 2: Validate story is ready for development
  validate:
    order: 2
    enabled: true
    execution: spawn
    type: bmad_workflow
    workflow: /bmad:bmm:workflows:implementation-readiness
    timeout: 3600
    on_failure: fix_and_retry
    retry:
      max: 2
      fix_prompt: "Fix the validation issues identified above"
    description: "Validate story has clear tasks and acceptance criteria"
    prompt: |
      /bmad:bmm:workflows:implementation-readiness
      {autonomy}

      {known_issues}

      Validate story is ready for development.
      Story file: {story_file}

      Check:
      - Clear acceptance criteria
      - Well-defined tasks
      - Dependencies documented

      Output: PASS or FAIL with details.

  # Stage 3: Develop the story
  develop:
    order: 3
    enabled: true
    execution: spawn
    type: bmad_workflow
    workflow: /bmad:bmm:workflows:dev-story
    timeout: 21600
    on_failure: fix_and_retry
    retry:
      max: 3
      fix_prompt: "Continue development, addressing any issues"
    description: "Implement the story following tasks in story file"
    prompt: |
      /bmad:bmm:workflows:dev-story
      {autonomy}

      {known_issues}

      Implement the story following tasks in the story file.
      Story file: {story_file}
      Story ID: {story_id}

      Follow red-green-refactor cycle for each task.
      Output: List of files changed and implementation summary.

  # Stage 4: Run linting (direct - lightweight)
  # Uses spawn agent to discover and run ALL lint checks the project uses
  lint:
    order: 4
    enabled: true
    execution: spawn
    type: lint_check
    timeout: 3600
    on_failure: fix_and_retry
    retry:
      max: 3
    description: "Discover and run all project lint checks"
    prompt: |
      {autonomy}

      {known_issues}

      PROJECT ROOT: {project_root}

      You are a dev agent responsible for running ALL lint/format checks this project uses and fixing any issues.

      STEP 1: DISCOVER LINT TOOLS
      First, discover what lint/format tools this project uses by checking:

      1. Read package.json scripts section - look for:
         - "lint", "lint:fix", "eslint"
         - "format", "format:check", "prettier"
         - "check", "validate"
         - Any script containing "lint", "format", "check"

      2. Check for config files that indicate tools:
         - .eslintrc.* or eslint.config.* → ESLint
         - .prettierrc.* or prettier.config.* → Prettier
         - biome.json or biome.jsonc → Biome
         - .stylelintrc.* → Stylelint
         - tslint.json → TSLint (deprecated)
         - .markdownlint.* → Markdownlint
         - .commitlintrc.* → Commitlint

      3. Check package.json devDependencies for:
         - eslint, @eslint/* → ESLint
         - prettier → Prettier
         - @biomejs/biome → Biome
         - stylelint → Stylelint
         - oxlint → OxLint

      STEP 2: RUN ALL LINT CHECKS
      Run each discovered lint check command. Common patterns:
      - npm run lint / pnpm lint / yarn lint
      - npm run format:check / pnpm format:check
      - npx eslint .
      - npx prettier --check .
      - npx biome check .

      STEP 3: FIX ALL ERRORS
      For each type of error found:

      A. ESLint/OxLint errors:
         - Read the file with errors
         - Fix code issues (unused vars, missing imports, etc.)
         - Use Edit tool to apply fixes

      B. Prettier/Biome formatting errors:
         - Run auto-fix command: `npx prettier --write <file>` or `npx biome format --write <file>`
         - If auto-fix unavailable, manually fix formatting

      C. Stylelint errors:
         - Read CSS/SCSS file
         - Fix style issues or run `npx stylelint --fix <file>`

      D. Other lint errors:
         - Read the error message carefully
         - Check if tool has --fix flag
         - Otherwise manually fix

      STEP 4: VERIFY ALL CHECKS PASS
      Re-run ALL discovered lint commands to ensure everything passes.

      Output:
      - List of lint tools discovered
      - Errors found and fixed
      - Final verification status

  # Stage 5: Run type checking (direct - lightweight)
  typecheck:
    order: 5
    enabled: true
    execution: direct
    type: bash
    command: "npm run typecheck"
    timeout: 3600
    on_failure: fix_and_retry
    retry:
      max: 2
      fix_agent: /bmad:bmm:agents:dev
      fix_prompt: "Fix the TypeScript type errors shown above"
    description: "Check TypeScript types"
    prompt: |
      {autonomy}

      {known_issues}

      PROJECT ROOT: {project_root}

      You are a dev agent fixing TypeScript type errors. The typecheck command `npm run typecheck` failed.

      TYPE ERRORS:
      ```
      {errors}
      ```

      INSTRUCTIONS:
      1. Parse the error output to identify files and line numbers with type errors
      2. Read each file that has errors using the Read tool
      3. Understand the type mismatch and fix the type annotations or code logic
      4. Use the Edit tool to apply fixes
      5. After fixing, run `npm run typecheck` to verify all errors are resolved

      Common fixes:
      - Add missing type annotations
      - Fix incorrect types (string vs number, etc.)
      - Add null checks for potentially undefined values
      - Import missing type definitions

      Output: Summary of files fixed and changes made.

  # Stage 6: Run unit tests (direct - lightweight)
  unit-test:
    order: 6
    enabled: true
    execution: direct
    type: bash
    command: "npm test"
    timeout: 3600
    on_failure: fix_and_retry
    retry:
      max: 3
      fix_agent: /bmad:bmm:agents:dev
      fix_prompt: "Fix the failing tests shown above"
    description: "Run all unit tests"
    prompt: |
      {autonomy}

      {known_issues}

      PROJECT ROOT: {project_root}

      You are a dev agent fixing failing unit tests. The test command `npm test` failed.

      TEST FAILURES:
      ```
      {errors}
      ```

      INSTRUCTIONS:
      1. Parse the error output to identify which tests failed and why
      2. Read the failing test file(s) using the Read tool
      3. Read the implementation file(s) being tested
      4. Determine if the bug is in the test or the implementation:
         - If the test expectation is wrong, fix the test
         - If the implementation is wrong, fix the implementation
      5. Use the Edit tool to apply fixes
      6. After fixing, run `npm test` to verify all tests pass

      Focus on fixing ONLY the failing tests. Do not add new tests or refactor passing code.

      Output: Summary of what was fixed (test or implementation) and changes made.

  # Stage 7: Code review (spawn - heavy workflow)
  code-review:
    order: 7
    enabled: true
    execution: spawn
    type: bmad_workflow
    workflow: /bmad:bmm:workflows:code-review
    timeout: 3600
    on_failure: continue
    blocking: false
    description: "Review code quality, security, and architecture"
    prompt: |
      /bmad:bmm:workflows:code-review
      {autonomy}

      {known_issues}

      Review the implemented code for story {story_id}.
      Files changed: {files_changed}

      Review for:
      - Code quality
      - Security issues
      - Performance
      - Architecture compliance

      Output: Findings with severity levels.

# Output variables captured from execution
output:
  - story_id
  - story_file
  - files_changed
  - lint_result
  - typecheck_result
  - test_results
  - review_findings
  - status
